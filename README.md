# ğŸ’ Diamond Naive Bayes Classifier

This project demonstrates the use of a **Bernoulli Naive Bayes classifier** to predict whether a diamond has an **Ideal cut** based on its physical characteristics.

We apply class balancing, polynomial feature expansion, and evaluate model performance with standard classification metrics.

---

## ğŸ“Š Project Objectives

- Predict **Ideal Cut** classification using:
  - Bernoulli Naive Bayes
- Handle class imbalance using **Random Undersampling**
- Extract meaningful features from physical attributes of diamonds

---

## ğŸ“ Dataset

- **Name**: Diamonds Dataset  
- **Source**: [Kaggle â€“ Diamonds by Shivam Bansal](https://www.kaggle.com/datasets/shivam2503/diamonds)

> Download the dataset and place it in the `data/` folder as `diamonds.csv`.

---

## ğŸ§ª Techniques Used

- Polynomial Feature Expansion (degree = 3)
- Data Standardization (`StandardScaler`)
- Class Balancing (`RandomUnderSampler`)
- Classification with `BernoulliNB(alpha=0.8)`
- Evaluation:
  - RÂ² Score
  - Matthews Correlation Coefficient (MCC)
  - Confusion Matrix
  - Classification Report

---

## ğŸ§± Project Structure

```
diamond-naive-bayes/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ diamonds.csv
â”‚
â”œâ”€â”€ Diamond_Naive_Bayes_Classifier.ipynb   # Full notebook
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## â–¶ï¸ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/mgedna/diamond-naive-bayes.git
   cd diamond-naive-bayes
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Place the dataset in `data/`:
   ```
   data/diamonds.csv
   ```

4. Launch the notebook:
   ```bash
   jupyter notebook Diamond_Naive_Bayes_Classifier.ipynb
   ```

---

## ğŸ‘¤ Author

**Edna Memedula** 
ğŸ“« [LinkedIn](https://www.linkedin.com/in/edna-memedula-24b519245) â€¢ [GitHub](https://github.com/mgedna) 
